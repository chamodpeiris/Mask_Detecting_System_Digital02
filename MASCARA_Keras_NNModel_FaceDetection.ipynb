{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mask Detection with Deep Learning\n",
        "\n",
        "This Jupyter Notebook implements a deep learning model for classifying images containing faces with or without masks. It utilizes transfer learning with MobileNetV2 and data augmentation techniques to improve generalization performance.\n",
        "\n",
        "**1. Imports**"
      ],
      "metadata": {
        "id": "RVMMn20Xv8R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dependencies\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pJanp-Zrv8R2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell imports necessary libraries for image processing, deep learning model building, data manipulation, and visualization.\n",
        "\n",
        "**2. Define Paths and Categories**"
      ],
      "metadata": {
        "id": "tMszjz44v8R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DIRECTORY = r\"C:\\Users\\Chamod Peiris\\Documents\\GitHub\\Projects_24\\Sys_MaskDetection\\data\"\n",
        "CATEGORIES = [\"with_mask\", \"without_mask\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "7Tb7q0M_v8R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines the directory containing the training images and the two categories (with_mask and without_mask). Update the `DIRECTORY` path to point to your actual data location.\n",
        "\n",
        "**3. Load and Preprocess Images**"
      ],
      "metadata": {
        "id": "CrXjdFmbv8R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "\tpath = os.path.join(DIRECTORY, category)\n",
        "\tfor img in os.listdir(path):\n",
        "\t\timg_path = os.path.join(path, img)\n",
        "\t\timage = load_img(img_path, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = preprocess_input(image)\n",
        "\n",
        "\t\tdata.append(image)\n",
        "\t\tlabels.append(category)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "y6BvoeBJv8R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section iterates through each category, loads images, resizes them to a fixed size (224x224 pixels), preprocesses them for the MobileNetV2 model (including normalization), and stores them in the `data` and `labels` lists.\n",
        "\n",
        "**4. Encode Labels and Split Data**"
      ],
      "metadata": {
        "id": "EXAVBK73v8R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode and convert to numpy array\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "(X_train, X_test, y_train, y_test) = train_test_split(data, labels,\n",
        "\ttest_size=0.25, stratify=labels, random_state=42)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "7UxwcSFYv8R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Label Binarizer is used to convert category labels (\"with_mask\" and \"without_mask\") into one-hot encoded vectors.\n",
        "- `to_categorical` transforms the one-hot encoded vectors into a binary matrix suitable for multi-class classification.\n",
        "- `train_test_split` splits the data into training and testing sets, maintaining the class distribution using stratification.\n",
        "\n",
        "**5. Data Augmentation**"
      ],
      "metadata": {
        "id": "QlhHL_48v8R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "cbPshPy6v8R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines an `ImageDataGenerator` object for data augmentation. Here, various transformations like rotation, zoom, shift, shear, and horizontal flip are applied to artificially increase the training data size and improve model robustness.\n",
        "\n",
        "**6. Define Model Architecture**"
      ],
      "metadata": {
        "id": "e0W-4pvav8R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-4\n",
        "\n",
        "# MobileNetV2 model without the head\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# Head model on top of the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "headModel = Dense(32, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"sigmoid\")(headModel)\n",
        "\n",
        "# Combine the base and head model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# loop over all layers in the base model and freeze head\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# compile our model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=INIT_LR),\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Z0fNw9y0v8R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This section defines the model architecture.\n",
        "  - A pre-trained MobileNetV2 model is loaded with its top layers excluded (transfer learning).\n",
        "  - A custom head model is created on top of the pre-trained base, consisting of average pooling, flattening, dense layers with ReLU activation, dropout for regularization, and a final output layer with sigmoid activation for binary classification.\n",
        "  - The base model layers are frozen to prevent retraining learned features, focusing on adapting the head model for the mask detection task.\n",
        "  - The model is compiled with binary cross-entropy loss for multi-class classification, Adam optimizer with an initial learning rate, and accuracy metric.\n",
        "  - Finally, the model summary is printed.\n",
        "\n",
        "**7. Train the Model**"
      ],
      "metadata": {
        "id": "w5bL9K2jv8R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "BS = 32\n",
        "\n",
        "# head model training\n",
        "H = model.fit(\n",
        "\taug.flow(X_train, y_train, batch_size=BS),\n",
        "\tsteps_per_epoch=len(X_train) // BS,\n",
        "\tvalidation_data=(X_test, y_test),\n",
        "\tvalidation_steps=len(y_test) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "predtest = model.predict(X_test, batch_size=BS)\n",
        "\n",
        "# index of the label with the corresponding largest predicted probability\n",
        "predtest = np.argmax(predtest, axis=1)\n",
        "\n",
        "# classification report\n",
        "print(classification_report(y_test.argmax(axis=1), predtest,\n",
        "\ttarget_names=lb.classes_))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9djEvvabv8R4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section defines the model training and the predictions;\n",
        "*   Model trained for 20 EPOCHS which took considerable time but ended up giving proper results.\n",
        "*   Predictions were quite good even the accuracy remains 0.99 at max.\n",
        "\n"
      ],
      "metadata": {
        "id": "9MGoptDsxRyk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}